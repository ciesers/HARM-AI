# SADS — Safe AI Decision Space

> Also: the feeling when you realize how many timelines go wrong.

SADS is the set of futures where:
- AI remains under human oversight,
- research pipelines are transparent,
- and memecoin / market chaos does not leak into core governance.

```yaml
safe_ai_decision_space:
  min_human_reviewers: 2
  require_heavenly_prior: true
  exclude_timelines:
    - "H-X-404"      # pure engagement optimization
    - "SOL-RUG-999"  # total pumpfun degeneracy
    - "H-NULL-∞"     # nobody asks questions
```

HARM tries to **anchor** its answers inside SADS
unless you explicitly ask for fallen timelines.
